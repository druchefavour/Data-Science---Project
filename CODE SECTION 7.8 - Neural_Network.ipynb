{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neural Networks\n",
    "In this section we will use Neural Networks to carry out classification on the natural gas data set. A neural network \"learns\" by solving an optimization problem to choose a set of parameters that minimizes an error function, which is typically a squared error loss. The neural network will attempt to find a \"sweet spot\": while the model is highly non-linear, its particular functional form allows for a computationally slick fitting procedure called \"backpropogation\". All we will do here is to \"learn\" by switching between computing the error using the training data and updating the weights by calculating the gradient of the error function. \n",
    "\n",
    "Let us write a class for NeuralNetworks, and we will then apply it to performing classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neural Network Class \n",
    "class Neural_Net:\n",
    "\n",
    "    #constructor initializes a new neural network with randomly selected weights and pre-specified height, and number of neurons per layer\n",
    "    def __init__(self,non,height):\n",
    "        #list to store the number of neurons in each layer of the network\n",
    "        self.num_of_neurons = non\n",
    "        #height of the network\n",
    "        self.L = height\n",
    "        #list to store number of weights in each layer of the network, indexed by layer, output neuron, input neuron\n",
    "        self.weights = numpy.zeros(shape=(10,10,10))\n",
    "        #delta_matrix: stores the gradient that is used in backpropagation\n",
    "        self.deltas = numpy.zeros(shape=(10,10))\n",
    "        #matrix that stores thresholded signals\n",
    "        self.signals = numpy.zeros(shape=(10,10))\n",
    "        #(tunable) learning_rate used in backpropagation\n",
    "        self.learning_rate = .001\n",
    "        #initialize weights to be between -2 and 2\n",
    "        for i in range(1,self.L+1):\n",
    "            for j in range(1,self.num_of_neurons[i]+1):\n",
    "                for k in range(self.num_of_neurons[i-1]+1):\n",
    "                    self.weights[i][j][k] = random.random()*4-2\n",
    "\n",
    "    #forward_pass computes the output of the neural network given an input\n",
    "    def forward_pass(self,x):\n",
    "        #(for convenience, we index neurons starting at 1 instead of zero)\n",
    "        self.signals[0][0] = -1\n",
    "        for i in range(1,self.num_of_neurons[0]+1):\n",
    "            self.signals[0][i] = x[i-1]\n",
    "        for i in range(1,self.L+1):\n",
    "            self.signals[i][0] = -1\n",
    "            for j in range(1,self.num_of_neurons[i]+1):\n",
    "                self.signals[i][j] = self.compute_signal(i,j)\n",
    "        return self.signals[self.L][1]\n",
    "\n",
    "    #tune_weights performs the backpropagation algorithm given a training example as input\n",
    "    def tune_weights(self,y):\n",
    "        self.deltas[self.L][1] = 2*(self.signals[self.L][1]-y)*(1-math.pow(self.signals[self.L][1],2))\n",
    "        for i in range(self.L-1,0,-1):\n",
    "            for j in range(1,self.num_of_neurons[i]+1):\n",
    "                self.deltas[i][j] = self.compute_delta(i,j)\n",
    "        for i in range(1,self.L+1):\n",
    "            for j in range(1,self.num_of_neurons[i]+1):\n",
    "                for k in range(self.num_of_neurons[i-1]+1):\n",
    "                    self.weights[i][j][k] = self.weights[i][j][k]-self.learning_rate*self.signals[i-1][k]*self.deltas[i][j]\n",
    "\n",
    "    #compute_signal: computes the delta for a given neuron at a given level\n",
    "    def compute_signal(self,level,neuron):\n",
    "        s = 0\n",
    "        for i in range(self.num_of_neurons[level-1]+1):\n",
    "            s += self.weights[level][neuron][i]*self.signals[level-1][i]\n",
    "        return self.g(s)\n",
    "    \n",
    "    #compute_delta: computes the signal s for a given neuron at a given level\n",
    "    def compute_delta(self,level,neuron):\n",
    "        s = 0\n",
    "        for j in range(1,self.num_of_neurons[level+1]+1):\n",
    "            s += self.weights[level+1][j][neuron]*self.deltas[level+1][j]\n",
    "        return (1-math.pow(self.signals[level][neuron],2))*s\n",
    "\n",
    "    #soft threshold function\n",
    "    def g(self,s):\n",
    "        return (math.exp(s)-math.exp(-s))/(math.exp(s)+math.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import math\n",
    "import scipy\n",
    "import random\n",
    "import brewer2mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a neural network and see how well it performs on the test and training sets from our natural gas dataset epoch by epoch. We instantiate a neural network with one hidden layer with four neurons, and a learning rate of .001. The learning rate is how much we scale the gradient in \"walking\" the parameter space.\n",
    "\n",
    "Let us load our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveCoalPrice</th>\n",
       "      <th>OilPrice</th>\n",
       "      <th>GrossGasProd</th>\n",
       "      <th>TotGasCons</th>\n",
       "      <th>GasPrice</th>\n",
       "      <th>Weather</th>\n",
       "      <th>WSTAT</th>\n",
       "      <th>GasPriceStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.22</td>\n",
       "      <td>41.12</td>\n",
       "      <td>2227.028</td>\n",
       "      <td>2399.702</td>\n",
       "      <td>5.82</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276</td>\n",
       "      <td>2009-01-31</td>\n",
       "      <td>54.37</td>\n",
       "      <td>41.71</td>\n",
       "      <td>2251.938</td>\n",
       "      <td>2729.715</td>\n",
       "      <td>5.24</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>2009-02-28</td>\n",
       "      <td>52.30</td>\n",
       "      <td>39.09</td>\n",
       "      <td>2074.167</td>\n",
       "      <td>2332.539</td>\n",
       "      <td>4.52</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335</td>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>44.34</td>\n",
       "      <td>47.94</td>\n",
       "      <td>2262.488</td>\n",
       "      <td>2170.709</td>\n",
       "      <td>3.96</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365</td>\n",
       "      <td>2009-04-30</td>\n",
       "      <td>41.92</td>\n",
       "      <td>49.65</td>\n",
       "      <td>2147.856</td>\n",
       "      <td>1741.293</td>\n",
       "      <td>3.50</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>0</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Days       Date  AveCoalPrice  OilPrice  GrossGasProd  TotGasCons  \\\n",
       "0   245 2008-12-31         57.22     41.12      2227.028    2399.702   \n",
       "1   276 2009-01-31         54.37     41.71      2251.938    2729.715   \n",
       "2   304 2009-02-28         52.30     39.09      2074.167    2332.539   \n",
       "3   335 2009-03-31         44.34     47.94      2262.488    2170.709   \n",
       "4   365 2009-04-30         41.92     49.65      2147.856    1741.293   \n",
       "\n",
       "   GasPrice Weather  WSTAT GasPriceStatus  \n",
       "0      5.82  WINTER      1           HIGH  \n",
       "1      5.24  WINTER      1           HIGH  \n",
       "2      4.52  WINTER      1           HIGH  \n",
       "3      3.96  WINTER      1           HIGH  \n",
       "4      3.50  SPRING      0           HIGH  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data for analysis\n",
    "dflog=pd.read_excel(\"data/DataSet_GasPrice_ Outlier_Removed.xlsx\")\n",
    "dflog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS</th>\n",
       "      <th>DATE</th>\n",
       "      <th>COALP</th>\n",
       "      <th>OILP</th>\n",
       "      <th>GPROD</th>\n",
       "      <th>GCONS</th>\n",
       "      <th>GASP</th>\n",
       "      <th>WEATH</th>\n",
       "      <th>WSTAT</th>\n",
       "      <th>GPSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.22</td>\n",
       "      <td>41.12</td>\n",
       "      <td>2227.028</td>\n",
       "      <td>2399.702</td>\n",
       "      <td>5.82</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276</td>\n",
       "      <td>2009-01-31</td>\n",
       "      <td>54.37</td>\n",
       "      <td>41.71</td>\n",
       "      <td>2251.938</td>\n",
       "      <td>2729.715</td>\n",
       "      <td>5.24</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>2009-02-28</td>\n",
       "      <td>52.30</td>\n",
       "      <td>39.09</td>\n",
       "      <td>2074.167</td>\n",
       "      <td>2332.539</td>\n",
       "      <td>4.52</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335</td>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>44.34</td>\n",
       "      <td>47.94</td>\n",
       "      <td>2262.488</td>\n",
       "      <td>2170.709</td>\n",
       "      <td>3.96</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365</td>\n",
       "      <td>2009-04-30</td>\n",
       "      <td>41.92</td>\n",
       "      <td>49.65</td>\n",
       "      <td>2147.856</td>\n",
       "      <td>1741.293</td>\n",
       "      <td>3.50</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>0</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAYS       DATE  COALP   OILP     GPROD     GCONS  GASP   WEATH  WSTAT  \\\n",
       "0   245 2008-12-31  57.22  41.12  2227.028  2399.702  5.82  WINTER      1   \n",
       "1   276 2009-01-31  54.37  41.71  2251.938  2729.715  5.24  WINTER      1   \n",
       "2   304 2009-02-28  52.30  39.09  2074.167  2332.539  4.52  WINTER      1   \n",
       "3   335 2009-03-31  44.34  47.94  2262.488  2170.709  3.96  WINTER      1   \n",
       "4   365 2009-04-30  41.92  49.65  2147.856  1741.293  3.50  SPRING      0   \n",
       "\n",
       "  GPSTAT  \n",
       "0   HIGH  \n",
       "1   HIGH  \n",
       "2   HIGH  \n",
       "3   HIGH  \n",
       "4   HIGH  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the columns name to create attributes and features\n",
    "dflog.columns = ['DAYS', 'DATE', 'COALP', 'OILP', 'GPROD', 'GCONS', 'GASP', 'WEATH', 'WSTAT', 'GPSTAT']\n",
    "dflog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(dflog[['GASP','GCONS']].values, \n",
    "                                              (dflog.WSTAT == 0).values,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtestlr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in the train and test dat, assuming csv format\n",
    "training = Xlr\n",
    "testing = Xtestlr\n",
    "\n",
    "#specify the number of neurons in each layer\n",
    "num_of_neurons = [1]\n",
    "\n",
    "#initialize a new neural network\n",
    "network = Neural_Net(num_of_neurons,0)\n",
    "\n",
    "#store the training error and test error during each epoch\n",
    "training_error = 0\n",
    "test_error = 0\n",
    "\n",
    "#store the training and test error for all epochs\n",
    "train = numpy.zeros(shape = (26))\n",
    "test = numpy.zeros(shape = (26))\n",
    "\n",
    "for epoch in range(26):\n",
    "    training_error = 0\n",
    "    test_error = 0\n",
    "    #compute the test errors\n",
    "    for j in range(26):\n",
    "        test_error = test_error+math.pow(network.forward_pass(testing[j]) - testing[j][1], 2)\n",
    "    #compute the training errors, SEQUENTIALLY. In other words, we perform backpropagation for *every* example\n",
    "    #instead of all at once. \n",
    "    for i in range(78):\n",
    "        training_error = training_error+math.pow(network.forward_pass(training[i])- training[i][1], 2)\n",
    "        network.tune_weights(training[i][0])   \n",
    "    training_error = training_error/78\n",
    "    test_error = test_error/26\n",
    "    train[epoch] = training_error\n",
    "    test[epoch]  = test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xd8350f0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEKCAYAAABQRFHsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKoNIklSVQSRJqsogkiRVZRBJkqr6/5HAagPybZleAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc70f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(numpy.arange(26), test, lw=2, label = 'test')\n",
    "ax.plot(numpy.arange(26), train, lw=2, label = 'train')\n",
    "ax.legend(loc=0)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
